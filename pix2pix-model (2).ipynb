{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"f696ee1b-7fb3-47ee-880d-5a87c4f2a2c4","_cell_guid":"da193ce2-2bf2-4e9e-b347-b8e5f1f3d08b","collapsed":false,"execution":{"iopub.status.busy":"2024-01-23T04:16:06.025958Z","iopub.execute_input":"2024-01-23T04:16:06.026381Z","iopub.status.idle":"2024-01-23T04:16:06.499886Z","shell.execute_reply.started":"2024-01-23T04:16:06.026343Z","shell.execute_reply":"2024-01-23T04:16:06.498496Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import zeros,ones\nfrom numpy.random import randint\nfrom keras.optimizers import Adam\nfrom keras.initializers import RandomNormal\nfrom keras.models import Model\n# from keras.models import Input\nfrom tensorflow.keras.layers import Input\nfrom keras.layers import Conv2D,Conv2DTranspose,LeakyReLU,Activation,Concatenate,Dropout,BatchNormalization\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras.utils import plot_model","metadata":{"_uuid":"33f791c2-ce6a-485a-80e3-3750b52d4791","_cell_guid":"7c649a07-cc74-49e7-bbfb-4b48c40cd033","collapsed":false,"execution":{"iopub.status.busy":"2024-01-23T04:20:28.814504Z","iopub.execute_input":"2024-01-23T04:20:28.814996Z","iopub.status.idle":"2024-01-23T04:20:28.823436Z","shell.execute_reply.started":"2024-01-23T04:20:28.814959Z","shell.execute_reply":"2024-01-23T04:20:28.822251Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_discriminator(image_shape):\n    init = RandomNormal(stddev = 0.2)\n    in_src_image = Input(shape = image_shape)\n    in_target_image = Input(shape = image_shape)\n    merged = Concatenate()([in_src_image,in_target_image])\n    \n    d = Conv2D(64,(4,4),strides = (2,2),padding = 'same',kernel_initializer = init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLu(alpha = 0.2)(d)\n    \n    d = Conv2D(128,(4,4),strides = (2,2),padding = 'same',kernel_initializer = init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLu(alpha = 0.2)(d)\n    \n    d = Conv2D(256,(4,4),strides = (2,2),padding = 'same',kernel_initializer = init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLu(alpha = 0.2)(d)\n    \n    d = Conv2D(512,(4,4),strides = (2,2),padding = 'same',kernel_initializer = init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLu(alpha = 0.2)(d)\n    \n    d = Conv2D(512,(4,4),padding = 'same',kernel_initializer = init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLu(alpha = 0.2)(d)\n    \n    d = Conv2D(1,(4,4),padding = 'same',kernel_initializer = init)(d)\n    patch_out = Activation('sigmoid')(d)\n    \n    #defining the model\n\n    model = Model([in_src_image,in_target_image],patch_out)\n    # compile model\n    opt = Adam(lr = 0.0002,beta_1 = 0.5)\n    model.compile(loss = 'binary_crossentropy',optimizer = opt,loss_weights = [0.5])\n    return model","metadata":{"_uuid":"1cb2d9d8-6c67-4c47-aab8-ead619f7521b","_cell_guid":"408919b4-76f7-4f5b-ba9b-9f23c9dca158","collapsed":false,"execution":{"iopub.status.busy":"2024-01-23T04:20:34.558745Z","iopub.execute_input":"2024-01-23T04:20:34.559159Z","iopub.status.idle":"2024-01-23T04:20:34.573067Z","shell.execute_reply.started":"2024-01-23T04:20:34.559111Z","shell.execute_reply":"2024-01-23T04:20:34.571864Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_encoder_block(layer_in,n_filters,batchnorm = True):\n    init = RandomNormal(stddev = 0.02)\n    g = Conv2D(n_filters,(4,4),strides = (2,2),padding = 'same',kernel_initializer = init)(g)\n    if batchnorm:\n        g = BatchNormalization()(g,training = True)\n    #leakyrelu acivation\n    g = LeakyReLu(alpha = 0.2)(g)\n    return g","metadata":{"_uuid":"2f906267-69b4-46f1-ac32-4c48c5a136d6","_cell_guid":"ad9b7156-5bdb-4437-83fd-e2946869f67b","collapsed":false,"execution":{"iopub.status.busy":"2024-01-23T04:20:41.982060Z","iopub.execute_input":"2024-01-23T04:20:41.982472Z","iopub.status.idle":"2024-01-23T04:20:41.989975Z","shell.execute_reply.started":"2024-01-23T04:20:41.982441Z","shell.execute_reply":"2024-01-23T04:20:41.988637Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decoder_block(layer_in,skip_in,n_filters,dropout = True):\n    init = RandomNormal(stddev = 0.02)\n    g = Conv2DTranspose(n_filters,(4,4),strides = (2,2),padding = 'same',kernel_initializer = init)(g)\n    g = BatchNormalization()(g,training = True)\n    if dropout:\n        g = Dropout(0.5)(g,training = True)\n        \n    #leakyrelu acivation\n    g = Concatenate()([g,skip_in])\n    g = Activation('relu')(g)\n    return g","metadata":{"_uuid":"606dbd13-5b9f-4eb3-8f81-31ed47df1284","_cell_guid":"1b720443-0508-4dc9-bcac-6c475c5858c4","collapsed":false,"execution":{"iopub.status.busy":"2024-01-23T04:20:45.684451Z","iopub.execute_input":"2024-01-23T04:20:45.684896Z","iopub.status.idle":"2024-01-23T04:20:45.692432Z","shell.execute_reply.started":"2024-01-23T04:20:45.684856Z","shell.execute_reply":"2024-01-23T04:20:45.691007Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_generator(image_shape = (256,256,3)):\n    init = RandomNormal(stddev = 0.02)\n    in_image = Input(shape = image_shape)\n    e1 = define_encoder_block(in_image,64,batchnorm = False)\n    e2 = define_encoder_block(e1,128)\n    e3 = define_encoder_block(e2,256)\n    e4 = define_encoder_block(e3,512)\n    e5 = define_encoder_block(e4,512)\n    e6 = define_encoder_block(e5,512)\n    e7 = define_encoder_block(e6,512)\n    \n    b = Conv2D(512,(4,4),strides = (2,2),padding = 'same',kernel_intializer =init)(b)\n    b = Activation('relu')(b)\n    \n    d1 = decoder_block(b,e7,512)\n    d2 = decoder_block(d1,e6,512)\n    d3 = decoder_block(d2,e5,512)\n    d4 = decoder_block(d3,e4,512,dropout = False)\n    d5 = decoder_block(d4,e3,256,dropout = False)\n    d6 = decoder_block(d5,e2,128,dropout = False)\n    d7 = decoder_block(d6,e1,64,dropout = False)\n    \n    g = Conv2DTranspose(image_shape[2],(4,4),strides = (2,2),padding = 'same',kernel_initializer = init)(g)\n    out_image = Activation('tanh')(g)\n    \n    model = Model(in_image,out_image)\n    return model","metadata":{"_uuid":"50007ffd-5595-4e66-81d3-c30ac6893f0b","_cell_guid":"f2b82119-02d5-46c0-915b-1fba70e33eca","collapsed":false,"execution":{"iopub.status.busy":"2024-01-23T04:20:48.614337Z","iopub.execute_input":"2024-01-23T04:20:48.614905Z","iopub.status.idle":"2024-01-23T04:20:48.627281Z","shell.execute_reply.started":"2024-01-23T04:20:48.614857Z","shell.execute_reply":"2024-01-23T04:20:48.625910Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_gan(g_model,d_model,image_shape):\n    for layer in d_model.layers:\n        if not isinstance(layer,BatchNormalization):\n            layer.trainable = False\n    in_src = Input(shape = image_shape)\n    gen_out = g_model(in_src)\n    dis_out = d_model([in_src,gen_out])\n    model = Model(in_src , [dis_out,gen_out])\n    opt = Adam(lr = 0.002,beta_1 = 0.5)\n    model.compile(loss = ['binary_crossentropy','mae'],optimizer = opt,loss_weights = [1,100])\n    return model","metadata":{"_uuid":"06281344-e400-4b6f-987f-217b5cd71393","_cell_guid":"7fcbcf99-db85-4445-9284-5e1b5b55af42","collapsed":false,"execution":{"iopub.status.busy":"2024-01-23T04:21:03.781533Z","iopub.execute_input":"2024-01-23T04:21:03.781962Z","iopub.status.idle":"2024-01-23T04:21:03.790404Z","shell.execute_reply.started":"2024-01-23T04:21:03.781928Z","shell.execute_reply":"2024-01-23T04:21:03.789012Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_real_samples(dataset,n_samples,patch_shape):\n    trainA,trainB = dataset\n    ix = randint(0,trainA.shape[0],n_samples)\n    X1,X2 = trainA[ix],trainB[ix]\n    y = ones((n_samples,patch_shape,patch_shape,1))\n    return [X1,X2],y","metadata":{"_uuid":"fda76074-8cdb-4350-8c23-c1d44c0ff177","_cell_guid":"ead97a08-181f-4d62-acf6-c242035a8eb8","collapsed":false,"execution":{"iopub.status.busy":"2024-01-23T04:21:05.907043Z","iopub.execute_input":"2024-01-23T04:21:05.907481Z","iopub.status.idle":"2024-01-23T04:21:05.915040Z","shell.execute_reply.started":"2024-01-23T04:21:05.907447Z","shell.execute_reply":"2024-01-23T04:21:05.913410Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_fake_samples(g_model,samples,patch_shape):\n    X = g_model.predict(samples)\n    y = zeros((len(X),patch_shape,patch_shape,1))\n    return X,y","metadata":{"_uuid":"f7b5b73f-bd22-4516-97a7-a1631b85ce89","_cell_guid":"7c4d20cc-8d77-4eed-b9cf-436f588b8db1","collapsed":false,"execution":{"iopub.status.busy":"2024-01-23T04:21:06.994657Z","iopub.execute_input":"2024-01-23T04:21:06.995096Z","iopub.status.idle":"2024-01-23T04:21:07.001441Z","shell.execute_reply.started":"2024-01-23T04:21:06.995062Z","shell.execute_reply":"2024-01-23T04:21:07.000213Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def summarize_performance(step,g_model,dataset,n_samples = 3):\n    [X_realA,X_realB],_ = generate_real_samples(dataset,n_samples,1)\n    X_fakeB, _ = generate_fake_samples(g_model,X_realA,1)\n    X_realA = (X_realA+1)/2.0\n    X_realB = (X_realB+1)/2.0\n    X_fakeB = (X_fakeB + 1)/2.0\n    \n    #lets now plot real source images\n    for i in range(n_samples):\n        plt.subplot(3,n_samples,1+i)\n        plt.axis('off')\n        plt.imshow(X_realA[i])\n    \n    #plot generated images\n    for i in range(n_samples):\n        plt.subplot(3,n_samples,1+n_samples + i)\n        plt.axis('off')\n        plt.imshow(X_fakeB[i])\n    \n    #plot real target images\n    for i in range(n_samples):\n        plt.subplot(3,n_samples,1+n_samples*2 + i)\n        plt.axis('off')\n        plt.imshow(X_realB[i])\n    \n    #save the plot to file\n    filename1 = 'images'%(step+1)\n    g_model.save(filename1)\n    print('saved files')","metadata":{"_uuid":"4aec3f3a-8d7d-46d5-a8ee-d0a1c9778aac","_cell_guid":"00002ae6-d694-4f64-88aa-a89e4df058a7","collapsed":false,"execution":{"iopub.status.busy":"2024-01-23T04:21:08.387109Z","iopub.execute_input":"2024-01-23T04:21:08.387574Z","iopub.status.idle":"2024-01-23T04:21:08.399098Z","shell.execute_reply.started":"2024-01-23T04:21:08.387539Z","shell.execute_reply":"2024-01-23T04:21:08.397797Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now train the pix2pix model","metadata":{"_uuid":"cff4c163-92de-446b-8ff0-1f5752dd77c6","_cell_guid":"a08be51e-af08-4841-b209-63d56cf0d3f9","trusted":true}},{"cell_type":"code","source":"def train(d_model,g_model,gan_model,dataset,n_epochs = 100,n_batch = 1):\n    n_patch = d_model.output_shape[1]\n    trainA,trainB = dataset\n    bat_per_epo = init(len(trainA)/n_batch)\n    \n    n_steps = bat_per_epo * n_epochs\n    for i in range(n_steps):\n        [X_realA,X_realB] , y_real = generate_real_samples(dataset,n_batch,n_patch)\n        #generate a batch of fake samples\n        X_fakeB,y_fake = generate_fake_samples(g_model,X_realA,n_patch)\n        \n        #update discriminator\n        d_loss1 = d_model.train_on_batch([X_realA,X_realB],y_real)\n        \n        d_loss2 = d_model.train_on_batch([X_realA,X_fakeB],y_fake)\n        \n        g_loss, _ , _ = gan_model.train_on_batch(X_realA,[y_real,X_realB])\n        if i%(bat_per_epo*10) == 0:\n            summarize_performance(i,g_model,dataset)","metadata":{"_uuid":"c3228341-6cbb-4c10-ba15-58cc6eaebc79","_cell_guid":"21a84d4e-135f-47df-abec-0e3e848cadc3","collapsed":false,"execution":{"iopub.status.busy":"2024-01-23T04:21:48.700362Z","iopub.execute_input":"2024-01-23T04:21:48.700848Z","iopub.status.idle":"2024-01-23T04:21:48.710467Z","shell.execute_reply.started":"2024-01-23T04:21:48.700813Z","shell.execute_reply":"2024-01-23T04:21:48.709203Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"3b9e1967-8ee9-4194-ae3a-3afd9dbd2f8b","_cell_guid":"d658fa02-db30-4c92-8995-971c847caa1c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"17b7acbd-b5b3-4540-ab66-bdd10b5643ef","_cell_guid":"19a559ea-e041-45ab-9685-fdf90b5c3d64","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}